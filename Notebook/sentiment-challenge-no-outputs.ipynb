{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Challenge: Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the machine learning model of your choice\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load the Sentiment140 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from Kaggle and specify the file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"label\", \"id\", \"date\", \"query\", \"user_name\", \"comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"id\", \"date\", \"query\", \"user_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Function to remove mentions (including the \"@\" symbol and the username)\n",
    "def remove_usernames_links(tweet):\n",
    "    tweet = re.sub('@[^\\s]+', '', tweet)\n",
    "    tweet = re.sub('http[^\\s]+', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "# Function to make text lowercase\n",
    "def make_lowercase(text):\n",
    "    return text.lower() if text else text\n",
    "\n",
    "# Remove rows with NaN and filter by comment length\n",
    "df = df.dropna()\n",
    "df = df[df[\"comment\"].str.len() > 50]\n",
    "\n",
    "# Apply the make_lowercase function to convert text to lowercase\n",
    "df['comment'] = df['comment'].apply(make_lowercase)\n",
    "\n",
    "# Remove special characters from comments\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text) if text else text\n",
    "\n",
    "# Apply the remove_mentions function to remove mentions\n",
    "df['comment'] = df['comment'].apply(remove_usernames_links)\n",
    "\n",
    "# Apply the remove_special_characters function to clean the comments\n",
    "df['comment'] = df['comment'].apply(remove_special_characters)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "df['comment'] = df['comment'].apply(lemmatize_text)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a feature extraction method (e.g., TF-IDF, Gensim, or a pretrained language model) and transform the text data into numerical features.\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['comment'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training-validation set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training-validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a machine learning model (e.g., Logistic Regression) and train it\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    \n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis on the dataset using your trained model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an AI company or product of your choice and collect tweets related to it\n",
    "# Use your trained model to predict sentiment on these tweets\n",
    "# Create visualizations to showcase sentiment (e.g., bar charts, word clouds)\n",
    "\n",
    "# Example: \n",
    "# - Visualize sentiment distribution using seaborn or matplotlib.\n",
    "# - Create word clouds for positive and negative tweets.\n",
    "# - Generate a bar chart showing sentiment scores for the chosen company/product.\n",
    "\n",
    "# Additional Tips:\n",
    "# - Experiment with hyperparameter tuning to improve model performance.\n",
    "# - Use cross-validation for a more robust evaluation.\n",
    "# - Write functions to encapsulate repetitive tasks and improve code organization.\n",
    "\n",
    "new_df =df[df['comment'].str.contains(\"amazon\")]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(new_df['comment'])\n",
    "y_true = new_df['label'].values \n",
    "y_pred = model.predict(X)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model's performance using metrics like accuracy, precision, recall, and F1-score.\n",
    "\n",
    "# Example:\n",
    "# - accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_true, y_pred))\n",
    "confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = new_df[new_df[\"label\"] == 0]\n",
    "pos_df = new_df[new_df[\"label\"] == 1]\n",
    "data = {\"Sentiment\": [\"Positive\", \"Negative\"], \"Count\": [len(pos_df), len(neg_df)]}\n",
    "sentiment_df = pd.DataFrame(data)\n",
    "\n",
    "print(sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(neg_df.head())\n",
    "display(pos_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \".join(new_df[\"comment\"].astype(str))\n",
    "neg_corpus = \" \".join(neg_df[\"comment\"].astype(str))\n",
    "pos_corpus = \" \".join(pos_df[\"comment\"].astype(str))\n",
    "from pprint import pprint\n",
    "pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud().generate(corpus)\n",
    "\n",
    "# Display the generated image:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate(neg_corpus)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate(pos_corpus)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Counting mosts common words and removing stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = re.findall(r'\\w+', corpus)\n",
    "filtered_words = [w for w in words if not w.lower() in stop_words]\n",
    "\n",
    "word_freq = Counter(filtered_words)\n",
    "most_common_words = word_freq.most_common(20)\n",
    "df = pd.DataFrame(most_common_words, columns=['Word', 'Frequency'])\n",
    "df = df[df[\"Word\"] != \"amazon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Frequency\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.bar(df, x=\"Word\", y=\"Frequency\", title=\"Word Frequency\", hover_name=\"Word\", color_discrete_sequence=[\"mediumslateblue\"])\n",
    "fig.update_layout(\n",
    "    title_font_color=\"mediumslateblue\",\n",
    "    plot_bgcolor=\"black\",\n",
    "    paper_bgcolor=\"black\",\n",
    "    xaxis=dict(\n",
    "        color=\"white\",\n",
    "        title_font=dict(color=\"mediumslateblue\"),\n",
    "        tickfont=dict(color=\"mediumslateblue\"),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        color=\"white\",\n",
    "        title_font=dict(color=\"mediumslateblue\"),\n",
    "        tickfont=dict(color=\"mediumslateblue\"),\n",
    "        showgrid=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative VS Positive Sentiment viz\n",
    "\n",
    "fig2 = px.bar(sentiment_df, x=\"Sentiment\", y=\"Count\", title=\"Negative VS Positive Sentiment, Amazon Tweets\", hover_name=\"Sentiment\", color_discrete_sequence=[\"mediumslateblue\"])\n",
    "fig2.update_layout(\n",
    "    title_font_color=\"mediumslateblue\",\n",
    "    plot_bgcolor=\"black\",\n",
    "    paper_bgcolor=\"black\",\n",
    "    xaxis=dict(\n",
    "        color=\"white\",\n",
    "        title_font=dict(color=\"mediumslateblue\"),\n",
    "        tickfont=dict(color=\"mediumslateblue\"),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        color=\"white\",\n",
    "        title_font=dict(color=\"mediumslateblue\"),\n",
    "        tickfont=dict(color=\"mediumslateblue\"),\n",
    "        showgrid=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
